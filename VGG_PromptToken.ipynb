{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LajdyU6Nt3R",
        "outputId": "7d28180b-3e7c-4157-cad0-9dc4aa4096b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "img = Image.open('/content/drive/MyDrive/Images/ABDUL_WAHEED.png')\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "\n",
        "img_tensor = transform(img)\n",
        "\n",
        "input_vector = img_tensor.view(-1)\n",
        "\n",
        "print(input_vector.shape)"
      ],
      "metadata": {
        "id": "nGj1R2U3bFBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd12c6b-b606-4d30-d672-898bdf59ce07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50176])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Load the image and convert it to grayscale\n",
        "img = Image.open('/content/drive/MyDrive/Images/ABDUL_WAHEED.png').convert('L')\n",
        "\n",
        "# Define the transform without Grayscale conversion\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Apply the transform to the image\n",
        "img_tensor = transform(img)\n",
        "\n",
        "# Load the pre-trained VGG model\n",
        "vgg_model = models.vgg16(pretrained=True)\n",
        "\n",
        "# Modify the first layer to accept 1 channel input\n",
        "vgg_model.features[0] = torch.nn.Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "\n",
        "# Remove the last fully connected layer\n",
        "vgg_model.classifier = vgg_model.classifier[:-1]\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "vgg_model.eval()\n",
        "\n",
        "# Pass the image tensor through the model\n",
        "with torch.no_grad():\n",
        "    features = vgg_model(img_tensor.unsqueeze(0))\n",
        "\n",
        "# Flatten the features\n",
        "input_vector = features.view(-1)\n",
        "\n",
        "# Now you can use these features to create a prompt token\n",
        "# This is a placeholder for the actual token creation logic\n",
        "prompt_token = input_vector\n",
        "\n",
        "print(prompt_token.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gKsIBIjN8lC",
        "outputId": "66012008-a7c4-4947-c622-22110b2b5786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4096])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SHsKalCwOCEW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}